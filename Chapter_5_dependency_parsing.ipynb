{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Chapter 5: Dependency parsing.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Chapter 5: Dependency parsing\n",
        "https://nlp100.github.io/en/ch05.html The zip archive ai.en.zip contains the text of the Wikipedia article, “Artificial Intelligence”. Apply a dependency parser to the text, and store the result in a file. Implement programs that read the dependency trees and perform the jobs.\n",
        "\n",
        "For your convenience, the zip archive also includes ai.en.txt.json, the text with dependency trees predicted by Stanford CoreNLP and stored in JSON format."
      ],
      "metadata": {
        "id": "HFuM1VYhYX1x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<hr>\n",
        "\n",
        "## 40. Read the parse result (words)\n",
        "\n",
        "Design a class Word that represents a word. This class has three member variables, text (word surface), lemma (lemma), and pos (part-of-speech). Represent a sentence as an array of instances of Word class. Implement a program to load the parse result, and store the text as an array of sentences. Show the object of the first sentence of the body of the article."
      ],
      "metadata": {
        "id": "1Sb1gRoCYeiZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P55J1SkzXo_1",
        "outputId": "0dadd308-7071-4a8f-e950-70a3a96e8ccf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "import pandas as pd\n",
        "import json\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "basePath = \"/content/drive/MyDrive/nlp100/Dataset/alice/\"\n",
        "rawtext = \"alice.txt\"\n",
        "conll = \"alice.txt.conll\"\n",
        "jsn = 'alice.txt.json'\n",
        "\n",
        "f = open(basePath + rawtext, 'r', encoding = \"ISO-8859-1\")\n",
        "aliceRaw = f.read()\n",
        "aliceRaw = re.sub(r\"\\n\", r\" \", aliceRaw)\n",
        "aliceRaw = aliceRaw.strip()\n",
        "aliceRawPerSentence = aliceRaw.split(\".\")\n",
        "\n",
        "f = open(basePath + jsn, 'r')\n",
        "aliceJson = json.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "aliceRaw[:500]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "Yk_dm5iPZUNe",
        "outputId": "8289aced-fcb9-4dbd-ab0d-f56c8f17f44d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"ALICE'S ADVENTURES IN WONDERLAND  Lewis Carroll  THE MILLENNIUM FULCRUM EDITION 3.0     CHAPTER I. Down the Rabbit-Hole  Alice was beginning to get very tired of sitting by her sister on the bank, and of having nothing to do: once or twice she had peeped into the book her sister was reading, but it had no pictures or conversations in it, 'and what is the use of a book,' thought Alice 'without pictures or conversations?'  So she was considering in her own mind (as well as she could, for the hot d\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Alice:\n",
        "  def __init__(self, pathJsn):\n",
        "    self._sentences = []\n",
        "    self._aliceJson = []\n",
        "\n",
        "    f = open(basePath + jsn, 'r')\n",
        "    self._aliceJson = json.load(f)\n",
        "\n",
        "    currentSentence = []\n",
        "\n",
        "    for i, sentence in enumerate(self._aliceJson['sentences']):\n",
        "      for j, word in enumerate(sentence['tokens']):\n",
        "        a = self.Word(\n",
        "            text = word['word'],\n",
        "            lemma = word['lemma'],\n",
        "            pos = word['pos'],\n",
        "        )\n",
        "        \n",
        "        currentSentence.append(a)\n",
        "\n",
        "      self._sentences.append(currentSentence)\n",
        "      currentSentence = []\n",
        "\n",
        "  class Word:\n",
        "    def __init__(self, text, lemma, pos):\n",
        "      self._text = text\n",
        "      self._lemma = lemma\n",
        "      self._pos = pos"
      ],
      "metadata": {
        "id": "gp0kzBAgZpTo"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "alice = Alice(basePath + jsn)\n",
        "\n",
        "for index, word in enumerate(alice._sentences[0]):\n",
        "  print(\"==== index\",index,\"====\")\n",
        "  print(\"text\\t:\", word._text)\n",
        "  print(\"lemma\\t:\",word._lemma)\n",
        "  print(\"pos\\t:\", word._pos)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pk6JxvuLlkMm",
        "outputId": "b994a31d-2c4a-4373-8880-9942d58e39ac"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==== index 0 ====\n",
            "text\t: ALICE\n",
            "lemma\t: ALICE\n",
            "pos\t: NNP\n",
            "==== index 1 ====\n",
            "text\t: 'S\n",
            "lemma\t: 's\n",
            "pos\t: POS\n",
            "==== index 2 ====\n",
            "text\t: ADVENTURES\n",
            "lemma\t: ADVENTURES\n",
            "pos\t: NNP\n",
            "==== index 3 ====\n",
            "text\t: IN\n",
            "lemma\t: in\n",
            "pos\t: IN\n",
            "==== index 4 ====\n",
            "text\t: WONDERLAND\n",
            "lemma\t: WONDERLAND\n",
            "pos\t: NNP\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<hr>\n",
        "\n",
        "## 41. Read the parse result (dependency)\n",
        "\n",
        "In addition to problem 40, add three member variables head (a reference to the object of its syntactic governor), dep (dependency type to its governor), and children (a list of references to the syntactic dependents in the parse tree) to the class Word. Show the pairs of governors (parents) and their dependents (children) of the first sentence of the body of the article. Use the class Word in the rest of the problems in this chapter."
      ],
      "metadata": {
        "id": "1Av20h77IJ5v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Alice:\n",
        "  def __init__(self, pathJsn):\n",
        "    self._sentences = []\n",
        "    self._aliceJson = []\n",
        "\n",
        "    f = open(basePath + jsn, 'r')\n",
        "    self._aliceJson = json.load(f)\n",
        "\n",
        "    currentSentence = []\n",
        "\n",
        "    for i, sentence in enumerate(self._aliceJson['sentences']):\n",
        "      for j, word in enumerate(sentence['tokens']):\n",
        "        a = self.Word(\n",
        "            text = word['word'],\n",
        "            lemma = word['lemma'],\n",
        "            pos = word['pos'],\n",
        "            head = sentence['enhancedPlusPlusDependencies'][j]['governorGloss'],\n",
        "            headId = sentence['enhancedPlusPlusDependencies'][j]['governor'],\n",
        "            dep = sentence['enhancedPlusPlusDependencies'][j]['dep'],\n",
        "            children = sentence['enhancedPlusPlusDependencies'][j]['dependentGloss'],\n",
        "            childrenId = sentence['enhancedPlusPlusDependencies'][j]['dependent']\n",
        "        )\n",
        "        \n",
        "        currentSentence.append(a)\n",
        "\n",
        "      self._sentences.append(currentSentence)\n",
        "      currentSentence = []\n",
        "\n",
        "  class Word:\n",
        "    def __init__(self, text, lemma, pos, head, headId, dep, children, childrenId):\n",
        "      self._text = text\n",
        "      self._lemma = lemma\n",
        "      self._pos = pos\n",
        "\n",
        "      self._head = head\n",
        "      self._headId = headId\n",
        "      self._dep = dep\n",
        "      self._children = children\n",
        "      self._childrenId = childrenId"
      ],
      "metadata": {
        "id": "mfPHLOPgWhyv"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "alice = Alice(basePath + jsn)\n",
        "\n",
        "for index, word in enumerate(alice._sentences[0]):\n",
        "  print(\"==== index\",index,\"====\")\n",
        "  print(\"text\\t:\", word._text)\n",
        "  print(\"lemma\\t:\",word._lemma)\n",
        "  print(\"pos\\t:\", word._pos)\n",
        "  print(\"head\\t:\", word._head)\n",
        "  print(\"dep\\t:\", word._dep)\n",
        "  print(\"children:\", word._children)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i8ozcrI6ht4N",
        "outputId": "ce8259d2-c693-4084-f5ec-feeac037657f"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==== index 0 ====\n",
            "text\t: ALICE\n",
            "lemma\t: ALICE\n",
            "pos\t: NNP\n",
            "head\t: ROOT\n",
            "dep\t: ROOT\n",
            "children: ADVENTURES\n",
            "==== index 1 ====\n",
            "text\t: 'S\n",
            "lemma\t: 's\n",
            "pos\t: POS\n",
            "head\t: ADVENTURES\n",
            "dep\t: nmod:poss\n",
            "children: ALICE\n",
            "==== index 2 ====\n",
            "text\t: ADVENTURES\n",
            "lemma\t: ADVENTURES\n",
            "pos\t: NNP\n",
            "head\t: ALICE\n",
            "dep\t: case\n",
            "children: 'S\n",
            "==== index 3 ====\n",
            "text\t: IN\n",
            "lemma\t: in\n",
            "pos\t: IN\n",
            "head\t: WONDERLAND\n",
            "dep\t: case\n",
            "children: IN\n",
            "==== index 4 ====\n",
            "text\t: WONDERLAND\n",
            "lemma\t: WONDERLAND\n",
            "pos\t: NNP\n",
            "head\t: ADVENTURES\n",
            "dep\t: nmod:in\n",
            "children: WONDERLAND\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<hr>\n",
        "\n",
        "## 42. Show root words\n",
        "For each sentence, extract the root word (whose head is ROOT)."
      ],
      "metadata": {
        "id": "LWiPgpl5IOIe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i, sentence in enumerate(alice._sentences[:4]):\n",
        "  for j, word in enumerate(sentence):\n",
        "    if word._head == 'ROOT':\n",
        "      print(word._text,\"is the root of sentence \",i)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jIk-X0XPik7A",
        "outputId": "d28edc3a-71a3-430f-b404-46c21c25bd87"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ALICE is the root of sentence  0\n",
            "Lewis is the root of sentence  1\n",
            "THE is the root of sentence  2\n",
            "CHAPTER is the root of sentence  3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<hr>\n",
        "\n",
        "## 43. Show verb governors and noun dependents\n",
        "Show all pairs of verb governors (parents) and their noun dependents (children) from all sentences in the text."
      ],
      "metadata": {
        "id": "KRuhENlxIXFD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i, sentence in enumerate(alice._sentences[:4]):\n",
        "  print(\"======= sentence\",i,\"=======\")\n",
        "  for j, word in enumerate(sentence):\n",
        "    print(\"parent\\t: \",word._head,\" \\t\\tchild\\t: \",word._children)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Hue5s-ckdiq",
        "outputId": "ba66c57f-23ce-4bcf-83fd-a24f5022c619"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======= sentence 0 =======\n",
            "parent\t:  ROOT  \t\tchild\t:  ADVENTURES\n",
            "parent\t:  ADVENTURES  \t\tchild\t:  ALICE\n",
            "parent\t:  ALICE  \t\tchild\t:  'S\n",
            "parent\t:  WONDERLAND  \t\tchild\t:  IN\n",
            "parent\t:  ADVENTURES  \t\tchild\t:  WONDERLAND\n",
            "======= sentence 1 =======\n",
            "parent\t:  ROOT  \t\tchild\t:  Carroll\n",
            "parent\t:  Carroll  \t\tchild\t:  Lewis\n",
            "======= sentence 2 =======\n",
            "parent\t:  ROOT  \t\tchild\t:  EDITION\n",
            "parent\t:  EDITION  \t\tchild\t:  THE\n",
            "parent\t:  EDITION  \t\tchild\t:  MILLENNIUM\n",
            "parent\t:  EDITION  \t\tchild\t:  FULCRUM\n",
            "parent\t:  EDITION  \t\tchild\t:  3.0\n",
            "======= sentence 3 =======\n",
            "parent\t:  ROOT  \t\tchild\t:  I.\n",
            "parent\t:  I.  \t\tchild\t:  CHAPTER\n",
            "parent\t:  Rabbit-Hole  \t\tchild\t:  Down\n",
            "parent\t:  Rabbit-Hole  \t\tchild\t:  the\n",
            "parent\t:  I.  \t\tchild\t:  Rabbit-Hole\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<hr>\n",
        "\n",
        "## 44. Visualize dependency trees\n",
        "Visualize a dependency tree of a sentence as a directed graph. Consider converting a dependency tree into DOT language and use Graphviz for drawing a directed graph. In addition, you can use pydot for drawing a dependency tree."
      ],
      "metadata": {
        "id": "L9vpUEsAIcu-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install treelib"
      ],
      "metadata": {
        "id": "KY4uS-YX1Uv4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from treelib import Node, Tree"
      ],
      "metadata": {
        "id": "zD3RLt1rl25r"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, sentence in enumerate(alice._sentences[:4]):\n",
        "  print(\"======= sentence\",i,\"=======\")\n",
        "\n",
        "  orderList = ['ROOT']\n",
        "  mapping = [''] # string '' will be removed later. Only for indexing\n",
        "  sentenceCopy = sentence.copy()\n",
        "  while len(orderList) != len(sentence) + 1: # DFS-ordering as treelib needs the data to be ordered.\n",
        "    for j, word in enumerate(sentenceCopy):\n",
        "      if word._head in orderList and word._children not in orderList:\n",
        "        indexInsert = orderList.index(word._head) + 1\n",
        "        orderList.insert(indexInsert, word._children)\n",
        "        mapping.insert(indexInsert, {'parent': word._head, 'child': word._children})\n",
        "        sentenceCopy.pop(j)\n",
        "\n",
        "  tree = Tree()\n",
        "  mapping.pop(0)\n",
        "\n",
        "  for i, v in enumerate(mapping):\n",
        "    if i == 0:\n",
        "      tree.create_node(v['child'], v['child'])\n",
        "    else:\n",
        "      tree.create_node(v['child'], v['child'], v['parent'])\n",
        "\n",
        "  tree.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HtxqDqxq2B_1",
        "outputId": "0153100a-f596-4c37-e2ed-25944509a48d"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======= sentence 0 =======\n",
            "ADVENTURES\n",
            "├── ALICE\n",
            "│   └── 'S\n",
            "└── WONDERLAND\n",
            "    └── IN\n",
            "\n",
            "======= sentence 1 =======\n",
            "Carroll\n",
            "└── Lewis\n",
            "\n",
            "======= sentence 2 =======\n",
            "EDITION\n",
            "├── 3.0\n",
            "├── FULCRUM\n",
            "├── MILLENNIUM\n",
            "└── THE\n",
            "\n",
            "======= sentence 3 =======\n",
            "I.\n",
            "├── CHAPTER\n",
            "└── Rabbit-Hole\n",
            "    ├── Down\n",
            "    └── the\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<hr>\n",
        "\n",
        "## 45. Triple with subject, verb, and direct object\n",
        "We are interested in extracting facts from the text. In this chapter, we represent a fact as a tuple of (subject, predicate, object). Extract tuples from dependency trees where:\n",
        "*   subject is a nominal subject of a verb in the past tense\n",
        "*   predicate is the verb in the past tense\n",
        "*   object is a direct object of the verb\n",
        "\n",
        "Consider an example sentence, “Frank Rosenblatt invented the perceptron”. We want to extract a tuple, (Rosenblatt, invented, perceptron), from the sentence. In this problem, we only consider a subject and object as a single word.\n",
        "\n",
        "This graph shows a dependency tree for the sentence (this may vary depending on the parser).\n",
        "\n",
        "<i> check the site for the image </i>\n",
        "\n",
        "In order to extract a tuple from a dependency tree, it may be a good idea to design an extraction rule on the dependency tree, for example,\n",
        "\n",
        "<i> check the site for the image </i>"
      ],
      "metadata": {
        "id": "eaCK-NVzIkTs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Rule: no restriction\n",
        "\n"
      ],
      "metadata": {
        "id": "kH-UkvP2D1oA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i, sentence in enumerate(alice._sentences):\n",
        "  vbds = []\n",
        "  vbdsId = [] # this Id is needed because some words occured multiple times (distinct each same word in a sentence)\n",
        "\n",
        "  for j, word in enumerate(sentence):\n",
        "    if word._pos == \"VBD\": \n",
        "      vbds.append(word._text)\n",
        "      vbdsId.append(j+1)\n",
        "\n",
        "  for e, vbd in enumerate(vbds):\n",
        "    subj = []\n",
        "    obj = []\n",
        "    \n",
        "    for j, word in enumerate(sentence):\n",
        "      if word._head == vbd and word._headId == vbdsId[e] and word._text != word._head and word._text not in [\",\", \"`\", \";\",\".\",\":\"]:\n",
        "        if word._dep == \"nsubj\": subj.append(word._text)\n",
        "        if word._dep == \"dobj\": obj.append(word._text)\n",
        "\n",
        "    if subj and obj:\n",
        "      print(i, subj, \"----\", vbd, \"----\", obj)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0-bZEHXbDanl",
        "outputId": "61a33b76-074d-4946-f9d2-5673c64d3d72"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4 ['conversations'] ---- had ---- ['what']\n",
            "9 ['actually'] ---- TOOK ---- ['OF']\n",
            "12 ['she'] ---- had ---- ['time']\n",
            "18 ['I'] ---- fell ---- ['top']\n",
            "48 ['she'] ---- put ---- ['way', 'it']\n",
            "55 ['she'] ---- turned ---- ['corner']\n",
            "59 ['she'] ---- tried ---- ['key']\n",
            "68 ['nice'] ---- had ---- ['cherry-tart']\n",
            "82 ['generally'] ---- gave ---- ['advice']\n",
            "82 ['she'] ---- followed ---- ['it']\n",
            "82 ['she'] ---- scolded ---- ['herself']\n",
            "89 ['same'] ---- remained ---- ['be']\n",
            "110 ['she'] ---- took ---- ['hurried']\n",
            "116 ['she'] ---- dried ---- ['eyes']\n",
            "140 ['hands'] ---- crossed ---- ['lap']\n",
            "155 ['just'] ---- dropped ---- ['to']\n",
            "156 ['That'] ---- WAS ---- ['escape']\n",
            "166 ['I'] ---- cried ---- ['much']\n",
            "197 ['always'] ---- HATED ---- ['cats']\n",
            "216 ['they'] ---- had ---- ['consultation']\n",
            "254 ['she'] ---- wanted ---- ['much']\n",
            "267 ['no'] ---- pulled ---- ['-LRB-']\n",
            "275 ['Dodo'] ---- presented ---- ['thimble']\n",
            "276 ['simply'] ---- took ---- ['looking']\n",
            "278 ['over'] ---- begged ---- ['to']\n",
            "305 ['only'] ---- shook ---- ['impatiently']\n",
            "307 ['Crab'] ---- took ---- ['opportunity']\n",
            "332 ['again'] ---- heard ---- ['pattering']\n",
            "332 ['she'] ---- looked ---- ['that']\n",
            "341 ['very'] ---- began ---- ['about']\n",
            "342 ['she'] ---- went ---- ['about']\n",
            "358 ['up'] ---- took ---- ['of']\n",
            "359 ['she'] ---- uncorked ---- ['put']\n",
            "362 ['she'] ---- had ---- ['bottle']\n",
            "363 ['hastily'] ---- put ---- ['bottle']\n",
            "366 ['effect'] ---- tried ---- ['with']\n",
            "373 ['that'] ---- fancied ---- ['of']\n",
            "389 ['she'] ---- shook ---- ['house']\n",
            "389 ['was'] ---- had ---- ['be']\n",
            "392 ['she'] ---- heard ---- ['Rabbit']\n",
            "393 ['she'] ---- heard ---- ['shriek', 'fall']\n",
            "408 ['ever'] ---- saw ---- ['size']\n",
            "414 ['out'] ---- made ---- ['in']\n",
            "422 ['Bill'] ---- got ---- ['other']\n",
            "429 ['who'] ---- did ---- ['that']\n",
            "463 ['of'] ---- found ---- ['little']\n",
            "465 ['all'] ---- made ---- ['rush']\n",
            "468 ['her'] ---- made ---- ['great']\n",
            "472 ['up'] ---- held ---- ['the']\n",
            "472 ['stick'] ---- made ---- ['head']\n",
            "472 ['side', 'game'] ---- ran ---- ['charges']\n",
            "472 ['running'] ---- began ---- ['time']\n",
            "475 ['leant'] ---- fanned ---- ['one']\n",
            "483 ['immediately'] ---- met ---- ['of']\n",
            "489 ['I'] ---- WAS ---- ['who']\n",
            "504 ['she'] ---- drew ---- ['up']\n",
            "516 ['she'] ---- had ---- ['nothing']\n",
            "517 ['it'] ---- unfolded ---- ['took']\n",
            "517 ['unfolded'] ---- took ---- ['its']\n",
            "527 ['a'] ---- turned ---- ['the']\n",
            "528 ['he'] ---- shook ---- ['locks']\n",
            "531 ['you'] ---- balanced ---- ['eel']\n",
            "552 ['it'] ---- put ---- ['into']\n",
            "561 ['stretched'] ---- broke ---- ['each']\n",
            "563 ['to'] ---- nibbled ---- ['of']\n",
            "565 ['she'] ---- did ---- ['last']\n",
            "577 ['be'] ---- found ---- ['which']\n",
            "586 [\"'ve\"] ---- tried ---- ['of']\n",
            "590 ['have'] ---- had ---- ['wink']\n",
            "601 ['she'] ---- remembered ---- ['number']\n",
            "607 ['you'] ---- tasted ---- ['egg']\n",
            "610 ['two'] ---- gave ---- ['adding']\n",
            "626 ['she'] ---- considered ---- ['him']\n",
            "627 ['footmen'] ---- had ---- ['hair']\n",
            "628 ['very'] ---- crept ---- ['out']\n",
            "640 ['we'] ---- had ---- ['door']\n",
            "674 ['quite'] ---- jumped ---- ['with']\n",
            "681 ['they'] ---- hit ---- ['her']\n",
            "685 ['everybody'] ---- minded ---- ['business']\n",
            "701 ['I'] ---- beat ---- ['him']\n",
            "710 ['it'] ---- missed ---- ['her']\n",
            "711 ['the'] ---- held ---- ['in', 'directions']\n",
            "713 ['it', 'into'] ---- carried ---- ['open']\n",
            "718 ['it'] ---- had ---- ['nose']\n",
            "730 ['it'] ---- saw ---- ['Alice']\n",
            "731 ['it'] ---- had ---- ['claws', 'teeth']\n",
            "740 ['she'] ---- tried ---- ['question']\n",
            "751 ['that'] ---- proved ---- ['it']\n",
            "775 ['pig'] ---- replied ---- ['Alice']\n",
            "781 ['some'] ---- raised ---- ['feet']\n",
            "824 ['I'] ---- told ---- ['you']\n",
            "841 ['he'] ---- poured ---- ['tea']\n",
            "858 ['for'] ---- said ---- ['Hatter']\n",
            "879 ['itself'] ---- began ---- ['its']\n",
            "903 ['slowly'] ---- opened ---- ['eyes']\n",
            "918 [\"'ve\"] ---- had ---- ['yet']\n",
            "923 ['she'] ---- helped ---- ['some']\n",
            "925 ['again'] ---- took ---- ['or', 'to']\n",
            "927 ['Hatter'] ---- went ---- ['!']\n",
            "941 ['Dormouse'] ---- followed ---- ['him']\n",
            "941 ['Alice'] ---- took ---- ['of']\n",
            "942 ['who', 'off'] ---- got ---- ['from']\n",
            "949 ['all'] ---- drew ---- ['--']\n",
            "958 ['the'] ---- took ---- ['going']\n",
            "958 ['they'] ---- saw ---- ['trying']\n",
            "960 ['she'] ---- picked ---- ['way']\n",
            "962 ['trees'] ---- had ---- ['door']\n",
            "976 ['Five', 'Seven'] ---- jogged ---- ['elbow']\n",
            "988 ['himself'] ---- checked ---- ['the']\n",
            "990 ['and', 'nothing'] ---- said ---- ['at']\n",
            "994 ['instantly'] ---- threw ---- ['themselves']\n",
            "1000 ['all'] ---- had ---- ['lie']\n",
            "1032 ['she'] ---- put ---- ['into']\n",
            "1045 ['Alice'] ---- joined ---- ['procession']\n",
            "1070 ['itself'] ---- WOULD ---- ['look']\n",
            "1070 ['of'] ---- had ---- ['away']\n",
            "1076 ['it'] ---- made ---- ['be']\n",
            "1081 ['put'] ---- began ---- ['the']\n",
            "1081 ['someone'] ---- had ---- ['listen']\n",
            "1107 ['caught'] ---- brought ---- ['the']\n",
            "1112 ['anything'] ---- had ---- ['could']\n",
            "1122 ['she'] ---- tucked ---- ['arm']\n",
            "1126 ['people'] ---- knew ---- ['that']\n",
            "1173 ['up'] ---- stood ---- ['in']\n",
            "1179 ['too'] ---- followed ---- ['croquet-ground']\n",
            "1188 ['never'] ---- saw ---- ['or']\n",
            "1209 ['they'] ---- saw ---- ['in']\n",
            "1212 ['he'] ---- got ---- ['sorrow']\n",
            "1252 ['could'] ---- wanted ---- ['much']\n",
            "1255 ['I'] ---- took ---- ['course']\n",
            "1268 ['else'] ---- had ---- ['to']\n",
            "1270 ['THAT'] ---- was ---- ['What']\n",
            "1273 ['never'] ---- learnt ---- ['it']\n",
            "1277 ['creatures'] ---- hid ---- ['in']\n",
            "1284 ['she'] ---- thought ---- ['it']\n",
            "1284 ['she'] ---- made ---- ['remark']\n",
            "1292 ['deeply'] ---- drew ---- ['of']\n",
            "1296 ['not'] ---- checked ---- ['and']\n",
            "1340 ['he'] ---- thanked ---- ['whiting']\n",
            "1351 ['she'] ---- checked ---- ['herself']\n",
            "1365 ['never'] ---- knew ---- ['much']\n",
            "1394 ['adventures'] ---- said ---- ['Alice', 'use']\n",
            "1398 ['she'] ---- saw ---- ['Rabbit']\n",
            "1399 ['got'] ---- opened ---- ['mouths', 'VERY']\n",
            "1399 ['as'] ---- gained ---- ['went']\n",
            "1400 ['different', 'breath'] ---- drew ---- ['said']\n",
            "1406 ['it'] ---- had ---- ['kind']\n",
            "1414 ['to'] ---- used ---- ['I']\n",
            "1415 ['never'] ---- heard ---- ['before']\n",
            "1428 ['Panther'] ---- took ---- ['pie-crust']\n",
            "1428 ['Owl'] ---- had ---- ['dish']\n",
            "1430 ['Turtle'] ---- interrupted ---- ['What']\n",
            "1436 ['Gryphon'] ---- said ---- ['that']\n",
            "1470 ['he'] ---- wore ---- ['crown']\n",
            "1472 ['her'] ---- knew ---- ['it']\n",
            "1487 ['she'] ---- went ---- ['got']\n",
            "1487 ['round'] ---- found ---- ['away']\n",
            "1488 ['mark'] ---- left ---- ['slate']\n",
            "1491 ['Rabbit'] ---- blew ---- ['the']\n",
            "1491 ['blew'] ---- unrolled ---- ['read']\n",
            "1492 ['he'] ---- stole ---- ['tarts']\n",
            "1497 ['Rabbit'] ---- blew ---- ['on']\n",
            "1500 ['I'] ---- finished ---- ['tea']\n",
            "1507 ['jury'] ---- wrote ---- ['their']\n",
            "1507 ['eagerly'] ---- added ---- ['and']\n",
            "1507 ['wrote'] ---- reduced ---- ['pence']\n",
            "1527 ['he'] ---- shook ---- ['shoes']\n",
            "1546 ['I'] ---- cut ---- ['bread-and-butter']\n",
            "1563 ['that'] ---- finished ---- ['guinea-pigs']\n",
            "1574 [\"n't\"] ---- said ---- ['cook']\n",
            "1601 ['soon'] ---- got ---- ['out']\n",
            "1601 ['got'] ---- put ---- ['right']\n",
            "1615 ['who'] ---- cackled ---- ['!']\n",
            "1622 ['you'] ---- invented ---- ['it']\n",
            "1625 ['pale'] ---- shut ---- ['hastily']\n",
            "1656 ['had'] ---- mentioned ---- ['him']\n",
            "1656 ['me'] ---- gave ---- ['said']\n",
            "1658 ['they'] ---- gave ---- ['two']\n",
            "1658 ['You'] ---- gave ---- ['three', 'more']\n",
            "1660 ['she'] ---- had ---- ['fit', 'obstacle']\n",
            "1661 ['she'] ---- liked ---- ['them']\n",
            "1673 ['certainly'] ---- did ---- ['he']\n",
            "1674 ['I'] ---- GAVE ---- ['HER']\n",
            "1674 ['THEY'] ---- GAVE ---- ['HIM']\n",
            "1674 ['he'] ---- did ---- ['what']\n",
            "1675 ['HIM'] ---- said ---- ['Alice']\n",
            "1683 ['it'] ---- made ---- ['mark']\n",
            "1704 ['she'] ---- gave ---- ['of']\n",
            "1707 ['I'] ---- had ---- ['dream']\n",
            "1708 ['dear'] ---- WAS ---- ['but']\n",
            "1710 ['she'] ---- left ---- ['her']\n",
            "1712 ['hurried'] ---- splashed ---- ['the']\n",
            "1713 ['on'] ---- believed ---- ['in']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Rule: subject must be NNP or NN\n"
      ],
      "metadata": {
        "id": "coM1YKpsENv4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i, sentence in enumerate(alice._sentences):\n",
        "  vbds = []\n",
        "  vbdsId = []\n",
        "\n",
        "  for j, word in enumerate(sentence):\n",
        "    if word._pos == \"VBD\": \n",
        "      vbds.append(word._text)\n",
        "      vbdsId.append(j+1)\n",
        "\n",
        "  for e, vbd in enumerate(vbds):\n",
        "    subj = []\n",
        "    obj = []\n",
        "    \n",
        "    for j, word in enumerate(sentence):\n",
        "      if word._head == vbd and word._headId == vbdsId[e] and word._text != word._head and word._text not in [\",\", \"`\", \";\",\".\",\":\"]:\n",
        "        if word._dep == \"nsubj\" and word._pos in [\"NNP\",\"NN\"]: subj.append(word._text)\n",
        "        if word._dep == \"dobj\": obj.append(word._text)\n",
        "\n",
        "    if subj and obj:\n",
        "      print(i, subj, \"----\", vbd, \"----\", obj)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u1_fmLVgEQxJ",
        "outputId": "337b96d6-f6ee-4855-e2d0-8f6f5369a090"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "275 ['Dodo'] ---- presented ---- ['thimble']\n",
            "307 ['Crab'] ---- took ---- ['opportunity']\n",
            "366 ['effect'] ---- tried ---- ['with']\n",
            "422 ['Bill'] ---- got ---- ['other']\n",
            "472 ['stick'] ---- made ---- ['head']\n",
            "472 ['side', 'game'] ---- ran ---- ['charges']\n",
            "685 ['everybody'] ---- minded ---- ['business']\n",
            "775 ['pig'] ---- replied ---- ['Alice']\n",
            "927 ['Hatter'] ---- went ---- ['!']\n",
            "941 ['Dormouse'] ---- followed ---- ['him']\n",
            "941 ['Alice'] ---- took ---- ['of']\n",
            "990 ['nothing'] ---- said ---- ['at']\n",
            "1045 ['Alice'] ---- joined ---- ['procession']\n",
            "1081 ['someone'] ---- had ---- ['listen']\n",
            "1112 ['anything'] ---- had ---- ['could']\n",
            "1400 ['breath'] ---- drew ---- ['said']\n",
            "1428 ['Panther'] ---- took ---- ['pie-crust']\n",
            "1428 ['Owl'] ---- had ---- ['dish']\n",
            "1430 ['Turtle'] ---- interrupted ---- ['What']\n",
            "1436 ['Gryphon'] ---- said ---- ['that']\n",
            "1488 ['mark'] ---- left ---- ['slate']\n",
            "1491 ['Rabbit'] ---- blew ---- ['the']\n",
            "1497 ['Rabbit'] ---- blew ---- ['on']\n",
            "1507 ['jury'] ---- wrote ---- ['their']\n",
            "1674 ['THEY'] ---- GAVE ---- ['HIM']\n",
            "1675 ['HIM'] ---- said ---- ['Alice']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Rule: subject must be NNP\n",
        "\n"
      ],
      "metadata": {
        "id": "1-K_sMEoD8yo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i, sentence in enumerate(alice._sentences):\n",
        "  vbds = []\n",
        "  vbdsId = []\n",
        "\n",
        "  for j, word in enumerate(sentence):\n",
        "    if word._pos == \"VBD\": \n",
        "      vbds.append(word._text)\n",
        "      vbdsId.append(j+1)\n",
        "\n",
        "  for e, vbd in enumerate(vbds):\n",
        "    subj = []\n",
        "    obj = []\n",
        "    \n",
        "    for j, word in enumerate(sentence):\n",
        "      if word._head == vbd and word._headId == vbdsId[e] and word._text != word._head and word._text not in [\",\", \"`\", \";\",\".\",\":\"]:\n",
        "        if word._dep == \"nsubj\" and word._pos == \"NNP\": subj.append(word._text)\n",
        "        if word._dep == \"dobj\": obj.append(word._text)\n",
        "  \n",
        "    if subj and obj:\n",
        "      print(i, subj, \"----\", vbd, \"----\", obj)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GyMwSyZt_L3O",
        "outputId": "0c878dd2-0c6c-4e67-d1db-01c8f92f429e"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "275 ['Dodo'] ---- presented ---- ['thimble']\n",
            "307 ['Crab'] ---- took ---- ['opportunity']\n",
            "422 ['Bill'] ---- got ---- ['other']\n",
            "941 ['Alice'] ---- took ---- ['of']\n",
            "1045 ['Alice'] ---- joined ---- ['procession']\n",
            "1430 ['Turtle'] ---- interrupted ---- ['What']\n",
            "1436 ['Gryphon'] ---- said ---- ['that']\n",
            "1491 ['Rabbit'] ---- blew ---- ['the']\n",
            "1497 ['Rabbit'] ---- blew ---- ['on']\n",
            "1674 ['THEY'] ---- GAVE ---- ['HIM']\n",
            "1675 ['HIM'] ---- said ---- ['Alice']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<hr>\n",
        "\n",
        "## 46. Expanding subjects and objects\n",
        "Improve the program of Problem 45 to remove the restriction that subjects and objects are single words but can also be phrases. For example, we want to extract (Frank Rosenblatt, invented, perceptron) from the sentence, “Frank Rosenblatt invented the perceptron”."
      ],
      "metadata": {
        "id": "MLNeL_a4I8Sa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Rule: no restriction"
      ],
      "metadata": {
        "id": "JLOhR6mSsgpv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i, sentence in enumerate(alice._sentences):\n",
        "  vbds = []\n",
        "  vbdsId = []\n",
        "\n",
        "  for j, word in enumerate(sentence):\n",
        "    if word._pos == \"VBD\": \n",
        "      vbds.append(word._text)\n",
        "      vbdsId.append(j+1)\n",
        "\n",
        "  for e, vbd in enumerate(vbds):\n",
        "    subj = []\n",
        "    obj = []\n",
        "    \n",
        "    for j, word in enumerate(sentence):\n",
        "      if word._head == vbd and word._headId == vbdsId[e] and word._text != word._head and word._text not in [\",\", \"`\", \";\",\".\",\":\"] :\n",
        "        if word._dep in [\"nsubj\", \"dobj\"]:\n",
        "          phrase = []\n",
        "          phrase.append(word._text)\n",
        "          prevIndex = j - 1\n",
        "          nextIndex = j + 1\n",
        "          \n",
        "          #lookback sub\n",
        "          currentWord = word._text\n",
        "          while prevIndex > 0 and sentence[prevIndex]._head == currentWord and sentence[prevIndex]._dep == \"compound\":\n",
        "            phrase.insert(0, sentence[prevIndex]._text)\n",
        "            currentWord = sentence[prevIndex]._text\n",
        "            prevIndex -= prevIndex\n",
        "\n",
        "          #lookfront sub\n",
        "          currentWord = word._text\n",
        "          if nextIndex < len(sentence):\n",
        "            while sentence[nextIndex]._head == currentWord and sentence[nextIndex]._dep == \"compound\":\n",
        "              phrase.append(sentence[nextIndex]._text)\n",
        "              currentWord = sentence[nextIndex]._text\n",
        "              nextIndex += nextIndex\n",
        "\n",
        "        if word._dep == \"nsubj\": \n",
        "          subj.append(\" \".join(phrase))\n",
        "        elif word._dep == \"dobj\":\n",
        "          obj.append(\" \".join(phrase))\n",
        "\n",
        "    if subj and obj:\n",
        "      print(i, subj, \"----\", vbd, \"----\", obj)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sm3E37nwEQGD",
        "outputId": "b6784323-eb0c-418b-9df9-7bd43a252169"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4 ['conversations'] ---- had ---- ['what']\n",
            "9 ['actually'] ---- TOOK ---- ['OF']\n",
            "12 ['she'] ---- had ---- ['time']\n",
            "18 ['I'] ---- fell ---- ['top']\n",
            "48 ['she'] ---- put ---- ['way', 'it']\n",
            "55 ['she'] ---- turned ---- ['corner']\n",
            "59 ['she'] ---- tried ---- ['key']\n",
            "68 ['nice'] ---- had ---- ['cherry-tart']\n",
            "82 ['generally'] ---- gave ---- ['advice']\n",
            "82 ['she'] ---- followed ---- ['it']\n",
            "82 ['she'] ---- scolded ---- ['herself']\n",
            "89 ['same'] ---- remained ---- ['be']\n",
            "110 ['she'] ---- took ---- ['hurried']\n",
            "116 ['she'] ---- dried ---- ['eyes']\n",
            "140 ['hands'] ---- crossed ---- ['lap']\n",
            "155 ['just'] ---- dropped ---- ['to']\n",
            "156 ['That'] ---- WAS ---- ['escape']\n",
            "166 ['I'] ---- cried ---- ['much']\n",
            "197 ['always'] ---- HATED ---- ['cats']\n",
            "216 ['they'] ---- had ---- ['consultation']\n",
            "254 ['she'] ---- wanted ---- ['much']\n",
            "267 ['no'] ---- pulled ---- ['-LRB-']\n",
            "275 ['Dodo'] ---- presented ---- ['thimble']\n",
            "276 ['simply'] ---- took ---- ['looking']\n",
            "278 ['over'] ---- begged ---- ['to']\n",
            "305 ['only'] ---- shook ---- ['impatiently']\n",
            "307 ['Crab'] ---- took ---- ['opportunity']\n",
            "332 ['again'] ---- heard ---- ['pattering']\n",
            "332 ['she'] ---- looked ---- ['that']\n",
            "341 ['very'] ---- began ---- ['about']\n",
            "342 ['she'] ---- went ---- ['about']\n",
            "358 ['up'] ---- took ---- ['of']\n",
            "359 ['she'] ---- uncorked ---- ['put']\n",
            "362 ['she'] ---- had ---- ['bottle']\n",
            "363 ['hastily'] ---- put ---- ['bottle']\n",
            "366 ['effect'] ---- tried ---- ['with']\n",
            "373 ['that'] ---- fancied ---- ['of']\n",
            "389 ['she'] ---- shook ---- ['house']\n",
            "389 ['was'] ---- had ---- ['be']\n",
            "392 ['she'] ---- heard ---- ['Rabbit']\n",
            "393 ['she'] ---- heard ---- ['shriek', 'fall']\n",
            "408 ['ever'] ---- saw ---- ['size']\n",
            "414 ['out'] ---- made ---- ['in']\n",
            "422 ['Bill'] ---- got ---- ['other']\n",
            "429 ['who'] ---- did ---- ['that']\n",
            "463 ['of'] ---- found ---- ['little']\n",
            "465 ['all'] ---- made ---- ['rush']\n",
            "468 ['her'] ---- made ---- ['great']\n",
            "472 ['up'] ---- held ---- ['the']\n",
            "472 ['stick'] ---- made ---- ['head']\n",
            "472 ['side', 'game'] ---- ran ---- ['charges']\n",
            "472 ['running'] ---- began ---- ['time']\n",
            "475 ['leant'] ---- fanned ---- ['one']\n",
            "483 ['immediately'] ---- met ---- ['of']\n",
            "489 ['I'] ---- WAS ---- ['who']\n",
            "504 ['she'] ---- drew ---- ['up']\n",
            "516 ['she'] ---- had ---- ['nothing']\n",
            "517 ['it'] ---- unfolded ---- ['took']\n",
            "517 ['unfolded'] ---- took ---- ['its']\n",
            "527 ['a'] ---- turned ---- ['the']\n",
            "528 ['he'] ---- shook ---- ['locks']\n",
            "531 ['you'] ---- balanced ---- ['eel']\n",
            "552 ['it'] ---- put ---- ['into']\n",
            "561 ['stretched'] ---- broke ---- ['each']\n",
            "563 ['to'] ---- nibbled ---- ['of']\n",
            "565 ['she'] ---- did ---- ['last']\n",
            "577 ['be'] ---- found ---- ['which']\n",
            "586 [\"'ve\"] ---- tried ---- ['of']\n",
            "590 ['have'] ---- had ---- ['wink']\n",
            "601 ['she'] ---- remembered ---- ['number']\n",
            "607 ['you'] ---- tasted ---- ['egg']\n",
            "610 ['two'] ---- gave ---- ['adding']\n",
            "626 ['she'] ---- considered ---- ['him']\n",
            "627 ['footmen'] ---- had ---- ['hair']\n",
            "628 ['very'] ---- crept ---- ['out']\n",
            "640 ['we'] ---- had ---- ['door']\n",
            "674 ['quite'] ---- jumped ---- ['with']\n",
            "681 ['they'] ---- hit ---- ['her']\n",
            "685 ['everybody'] ---- minded ---- ['business']\n",
            "701 ['I'] ---- beat ---- ['him']\n",
            "710 ['it'] ---- missed ---- ['her']\n",
            "711 ['the'] ---- held ---- ['in', 'directions']\n",
            "713 ['it', 'into'] ---- carried ---- ['open']\n",
            "718 ['it'] ---- had ---- ['nose']\n",
            "730 ['it'] ---- saw ---- ['Alice']\n",
            "731 ['it'] ---- had ---- ['claws', 'teeth']\n",
            "740 ['she'] ---- tried ---- ['question']\n",
            "751 ['that'] ---- proved ---- ['it']\n",
            "775 ['pig'] ---- replied ---- ['Alice']\n",
            "781 ['some'] ---- raised ---- ['feet']\n",
            "824 ['I'] ---- told ---- ['you']\n",
            "841 ['he'] ---- poured ---- ['tea']\n",
            "858 ['for'] ---- said ---- ['Hatter']\n",
            "879 ['itself'] ---- began ---- ['its']\n",
            "903 ['slowly'] ---- opened ---- ['eyes']\n",
            "918 [\"'ve\"] ---- had ---- ['yet']\n",
            "923 ['she'] ---- helped ---- ['some']\n",
            "925 ['again'] ---- took ---- ['or', 'to']\n",
            "927 ['Hatter'] ---- went ---- ['!']\n",
            "941 ['Dormouse'] ---- followed ---- ['him']\n",
            "941 ['Alice'] ---- took ---- ['of']\n",
            "942 ['who', 'off'] ---- got ---- ['from']\n",
            "949 ['all'] ---- drew ---- ['--']\n",
            "958 ['the'] ---- took ---- ['going']\n",
            "958 ['they'] ---- saw ---- ['trying']\n",
            "960 ['she'] ---- picked ---- ['way']\n",
            "962 ['trees'] ---- had ---- ['door']\n",
            "976 ['Five', 'Seven'] ---- jogged ---- ['elbow']\n",
            "988 ['himself'] ---- checked ---- ['the']\n",
            "990 ['and', 'nothing'] ---- said ---- ['at']\n",
            "994 ['instantly'] ---- threw ---- ['themselves']\n",
            "1000 ['all'] ---- had ---- ['lie']\n",
            "1032 ['she'] ---- put ---- ['into']\n",
            "1045 ['Alice'] ---- joined ---- ['procession']\n",
            "1070 ['itself'] ---- WOULD ---- ['look']\n",
            "1070 ['of'] ---- had ---- ['away']\n",
            "1076 ['it'] ---- made ---- ['be']\n",
            "1081 ['put'] ---- began ---- ['the']\n",
            "1081 ['someone'] ---- had ---- ['listen']\n",
            "1107 ['caught'] ---- brought ---- ['the']\n",
            "1112 ['anything'] ---- had ---- ['could']\n",
            "1122 ['she'] ---- tucked ---- ['arm']\n",
            "1126 ['people'] ---- knew ---- ['that']\n",
            "1173 ['up'] ---- stood ---- ['in']\n",
            "1179 ['too'] ---- followed ---- ['croquet-ground']\n",
            "1188 ['never'] ---- saw ---- ['or']\n",
            "1209 ['they'] ---- saw ---- ['in']\n",
            "1212 ['he'] ---- got ---- ['sorrow']\n",
            "1252 ['could'] ---- wanted ---- ['much']\n",
            "1255 ['I'] ---- took ---- ['course']\n",
            "1268 ['else'] ---- had ---- ['to']\n",
            "1270 ['THAT'] ---- was ---- ['What']\n",
            "1273 ['never'] ---- learnt ---- ['it']\n",
            "1277 ['creatures'] ---- hid ---- ['in']\n",
            "1284 ['she'] ---- thought ---- ['it']\n",
            "1284 ['she'] ---- made ---- ['remark']\n",
            "1292 ['deeply'] ---- drew ---- ['of']\n",
            "1296 ['not'] ---- checked ---- ['and']\n",
            "1340 ['he'] ---- thanked ---- ['whiting']\n",
            "1351 ['she'] ---- checked ---- ['herself']\n",
            "1365 ['never'] ---- knew ---- ['much']\n",
            "1394 ['adventures'] ---- said ---- ['Alice', 'use']\n",
            "1398 ['she'] ---- saw ---- ['White Rabbit']\n",
            "1399 ['got'] ---- opened ---- ['mouths', 'VERY']\n",
            "1399 ['as'] ---- gained ---- ['went']\n",
            "1400 ['different', 'breath'] ---- drew ---- ['said']\n",
            "1406 ['it'] ---- had ---- ['kind']\n",
            "1414 ['to'] ---- used ---- ['I']\n",
            "1415 ['never'] ---- heard ---- ['before']\n",
            "1428 ['Panther'] ---- took ---- ['pie-crust']\n",
            "1428 ['Owl'] ---- had ---- ['dish']\n",
            "1430 ['Mock Turtle'] ---- interrupted ---- ['What']\n",
            "1436 ['Gryphon'] ---- said ---- ['that']\n",
            "1470 ['he'] ---- wore ---- ['crown']\n",
            "1472 ['her'] ---- knew ---- ['it']\n",
            "1487 ['she'] ---- went ---- ['got']\n",
            "1487 ['round'] ---- found ---- ['away']\n",
            "1488 ['mark'] ---- left ---- ['slate']\n",
            "1491 ['White Rabbit'] ---- blew ---- ['the']\n",
            "1491 ['blew'] ---- unrolled ---- ['read']\n",
            "1492 ['he'] ---- stole ---- ['tarts']\n",
            "1497 ['White Rabbit'] ---- blew ---- ['on']\n",
            "1500 ['I'] ---- finished ---- ['tea']\n",
            "1507 ['jury'] ---- wrote ---- ['their']\n",
            "1507 ['eagerly'] ---- added ---- ['and']\n",
            "1507 ['wrote'] ---- reduced ---- ['pence']\n",
            "1527 ['he'] ---- shook ---- ['shoes']\n",
            "1546 ['I'] ---- cut ---- ['bread-and-butter']\n",
            "1563 ['that'] ---- finished ---- ['guinea-pigs']\n",
            "1574 [\"n't\"] ---- said ---- ['cook']\n",
            "1601 ['soon'] ---- got ---- ['out']\n",
            "1601 ['got'] ---- put ---- ['right']\n",
            "1615 ['who'] ---- cackled ---- ['!']\n",
            "1622 ['you'] ---- invented ---- ['it']\n",
            "1625 ['pale'] ---- shut ---- ['hastily']\n",
            "1656 ['had'] ---- mentioned ---- ['him']\n",
            "1656 ['me'] ---- gave ---- ['said']\n",
            "1658 ['they'] ---- gave ---- ['two']\n",
            "1658 ['You'] ---- gave ---- ['three', 'more']\n",
            "1660 ['she'] ---- had ---- ['fit', 'obstacle']\n",
            "1661 ['she'] ---- liked ---- ['them']\n",
            "1673 ['certainly'] ---- did ---- ['he']\n",
            "1674 ['I'] ---- GAVE ---- ['HER']\n",
            "1674 ['THEY'] ---- GAVE ---- ['HIM']\n",
            "1674 ['he'] ---- did ---- ['what']\n",
            "1675 ['HIM'] ---- said ---- ['Alice']\n",
            "1683 ['it'] ---- made ---- ['mark']\n",
            "1704 ['she'] ---- gave ---- ['of']\n",
            "1707 ['I'] ---- had ---- ['dream']\n",
            "1708 ['dear'] ---- WAS ---- ['but']\n",
            "1710 ['she'] ---- left ---- ['her']\n",
            "1712 ['hurried'] ---- splashed ---- ['the']\n",
            "1713 ['on'] ---- believed ---- ['in']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Rule: subject must be NN or NNP"
      ],
      "metadata": {
        "id": "lGA8KDn2Mz82"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i, sentence in enumerate(alice._sentences):\n",
        "  vbds = []\n",
        "  vbdsId = []\n",
        "\n",
        "  for j, word in enumerate(sentence):\n",
        "    if word._pos == \"VBD\": \n",
        "      vbds.append(word._text)\n",
        "      vbdsId.append(j+1)\n",
        "\n",
        "  for e, vbd in enumerate(vbds):\n",
        "    subj = []\n",
        "    obj = []\n",
        "    \n",
        "    for j, word in enumerate(sentence):\n",
        "      if word._head == vbd and word._headId == vbdsId[e] and word._text != word._head and word._text not in [\",\", \"`\", \";\",\".\",\":\"]:\n",
        "        if word._dep == \"nsubj\" and word._pos in [\"NNP\", \"NN\"]: \n",
        "          phrase = []\n",
        "          phrase.append(word._text)\n",
        "          prevIndex = j - 1\n",
        "          nextIndex = j + 1\n",
        "          \n",
        "          #lookback sub\n",
        "          currentWord = word._text\n",
        "          while prevIndex > 0 and sentence[prevIndex]._head == currentWord and sentence[prevIndex]._dep == \"compound\":\n",
        "            phrase.insert(0, sentence[prevIndex]._text)\n",
        "            currentWord = sentence[prevIndex]._text\n",
        "            prevIndex -= prevIndex\n",
        "\n",
        "          #lookfront sub\n",
        "          currentWord = word._text\n",
        "          if nextIndex < len(sentence):\n",
        "            while sentence[nextIndex]._head == currentWord and sentence[nextIndex]._dep == \"compound\":\n",
        "              phrase.append(sentence[nextIndex]._text)\n",
        "              currentWord = sentence[nextIndex]._text\n",
        "              nextIndex += nextIndex\n",
        "\n",
        "          subj.append(\" \".join(phrase))\n",
        "\n",
        "        if word._dep == \"dobj\":\n",
        "          phrase = []\n",
        "          phrase.append(word._text)\n",
        "          prevIndex = j - 1\n",
        "          nextIndex = j + 1\n",
        "          \n",
        "          #lookback sub\n",
        "          currentWord = word._text\n",
        "          while prevIndex > 0 and sentence[prevIndex]._head == currentWord and sentence[prevIndex]._dep == \"compound\":\n",
        "            phrase.insert(0, sentence[prevIndex]._text)\n",
        "            currentWord = sentence[prevIndex]._text\n",
        "            prevIndex -= prevIndex\n",
        "\n",
        "          #lookfront sub\n",
        "          currentWord = word._text\n",
        "          if nextIndex < len(sentence):\n",
        "            while sentence[nextIndex]._head == currentWord and sentence[nextIndex]._dep == \"compound\":\n",
        "              phrase.append(sentence[nextIndex]._text)\n",
        "              currentWord = sentence[nextIndex]._text\n",
        "              nextIndex += nextIndex\n",
        "\n",
        "          obj.append(\" \".join(phrase))\n",
        "\n",
        "    if subj and obj:\n",
        "      print(i, subj, \"----\", vbd, \"----\", obj)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uIDzRnb7M2MX",
        "outputId": "1e52f074-969a-4d3b-d4a9-b2665ef1f54b"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "275 ['Dodo'] ---- presented ---- ['thimble']\n",
            "307 ['Crab'] ---- took ---- ['opportunity']\n",
            "366 ['effect'] ---- tried ---- ['with']\n",
            "422 ['Bill'] ---- got ---- ['other']\n",
            "472 ['stick'] ---- made ---- ['head']\n",
            "472 ['side', 'game'] ---- ran ---- ['charges']\n",
            "685 ['everybody'] ---- minded ---- ['business']\n",
            "775 ['pig'] ---- replied ---- ['Alice']\n",
            "927 ['Hatter'] ---- went ---- ['!']\n",
            "941 ['Dormouse'] ---- followed ---- ['him']\n",
            "941 ['Alice'] ---- took ---- ['of']\n",
            "990 ['nothing'] ---- said ---- ['at']\n",
            "1045 ['Alice'] ---- joined ---- ['procession']\n",
            "1081 ['someone'] ---- had ---- ['listen']\n",
            "1112 ['anything'] ---- had ---- ['could']\n",
            "1400 ['breath'] ---- drew ---- ['said']\n",
            "1428 ['Panther'] ---- took ---- ['pie-crust']\n",
            "1428 ['Owl'] ---- had ---- ['dish']\n",
            "1430 ['Mock Turtle'] ---- interrupted ---- ['What']\n",
            "1436 ['Gryphon'] ---- said ---- ['that']\n",
            "1488 ['mark'] ---- left ---- ['slate']\n",
            "1491 ['White Rabbit'] ---- blew ---- ['the']\n",
            "1497 ['White Rabbit'] ---- blew ---- ['on']\n",
            "1507 ['jury'] ---- wrote ---- ['their']\n",
            "1674 ['THEY'] ---- GAVE ---- ['HIM']\n",
            "1675 ['HIM'] ---- said ---- ['Alice']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Rule: subject must be NNP\n"
      ],
      "metadata": {
        "id": "ATuVvA6HE13d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i, sentence in enumerate(alice._sentences):\n",
        "  vbds = []\n",
        "  vbdsId = []\n",
        "\n",
        "  for j, word in enumerate(sentence):\n",
        "    if word._pos == \"VBD\": \n",
        "      vbds.append(word._text)\n",
        "      vbdsId.append(j+1)\n",
        "\n",
        "  for e, vbd in enumerate(vbds):\n",
        "    subj = []\n",
        "    obj = []\n",
        "    \n",
        "    for j, word in enumerate(sentence):\n",
        "      if word._head == vbd and word._headId == vbdsId[e] and word._text != word._head and word._text not in [\",\", \"`\", \";\",\".\",\":\"]:\n",
        "        if word._dep == \"nsubj\" and word._pos == \"NNP\": \n",
        "          phrase = []\n",
        "          phrase.append(word._text)\n",
        "          prevIndex = j - 1\n",
        "          nextIndex = j + 1\n",
        "          \n",
        "          #lookback sub\n",
        "          currentWord = word._text\n",
        "          while prevIndex > 0 and sentence[prevIndex]._head == currentWord and sentence[prevIndex]._dep == \"compound\":\n",
        "            phrase.insert(0, sentence[prevIndex]._text)\n",
        "            currentWord = sentence[prevIndex]._text\n",
        "            prevIndex -= prevIndex\n",
        "\n",
        "          #lookfront sub\n",
        "          currentWord = word._text\n",
        "          if nextIndex < len(sentence):\n",
        "            while sentence[nextIndex]._head == currentWord and sentence[nextIndex]._dep == \"compound\":\n",
        "              phrase.append(sentence[nextIndex]._text)\n",
        "              currentWord = sentence[nextIndex]._text\n",
        "              nextIndex += nextIndex\n",
        "\n",
        "          subj.append(\" \".join(phrase))\n",
        "\n",
        "        if word._dep == \"dobj\":\n",
        "          phrase = []\n",
        "          phrase.append(word._text)\n",
        "          prevIndex = j - 1\n",
        "          nextIndex = j + 1\n",
        "          \n",
        "          #lookback sub\n",
        "          currentWord = word._text\n",
        "          while prevIndex > 0 and sentence[prevIndex]._head == currentWord and sentence[prevIndex]._dep == \"compound\":\n",
        "            phrase.insert(0, sentence[prevIndex]._text)\n",
        "            currentWord = sentence[prevIndex]._text\n",
        "            prevIndex -= prevIndex\n",
        "\n",
        "          #lookfront sub\n",
        "          currentWord = word._text\n",
        "          if nextIndex < len(sentence):\n",
        "            while sentence[nextIndex]._head == currentWord and sentence[nextIndex]._dep == \"compound\":\n",
        "              phrase.append(sentence[nextIndex]._text)\n",
        "              currentWord = sentence[nextIndex]._text\n",
        "              nextIndex += nextIndex\n",
        "\n",
        "          obj.append(\" \".join(phrase))\n",
        "\n",
        "    if subj and obj:\n",
        "      print(i, subj, \"----\", vbd, \"----\", obj)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d2XUJ_SsGKlG",
        "outputId": "12196ed8-d9f2-4f89-ac14-f027490e83ee"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "275 ['Dodo'] ---- presented ---- ['thimble']\n",
            "307 ['Crab'] ---- took ---- ['opportunity']\n",
            "422 ['Bill'] ---- got ---- ['other']\n",
            "941 ['Alice'] ---- took ---- ['of']\n",
            "1045 ['Alice'] ---- joined ---- ['procession']\n",
            "1430 ['Mock Turtle'] ---- interrupted ---- ['What']\n",
            "1436 ['Gryphon'] ---- said ---- ['that']\n",
            "1491 ['White Rabbit'] ---- blew ---- ['the']\n",
            "1497 ['White Rabbit'] ---- blew ---- ['on']\n",
            "1674 ['THEY'] ---- GAVE ---- ['HIM']\n",
            "1675 ['HIM'] ---- said ---- ['Alice']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<hr>\n",
        "\n",
        "## 47. Triple from the passive sentence\n",
        "Extract facts from sentences in the passive voice. Consider an example sentence, “Artificial intelligence was founded as an academic discipline in 1955”. We want to extract two tuples from the sentence,\n",
        "\n",
        "* (Artificial intelligence, founded-as, academic discipline)\n",
        "* (Artificial intelligence, founded-in, 1955)"
      ],
      "metadata": {
        "id": "jWtjRYCAJC5T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<hr>\n",
        "\n",
        "## 48. Extract paths from the root to nouns\n",
        "For every noun in a dependency tree, extract a path from the root to the noun. Here, each path must satisfy the following specifications.\n",
        "\n",
        "* Nodes in a path are words in surface form\n",
        "* Nodes are connected with “ -> “ from the root to the leaf node\n",
        "* We don’t have to include dependency types (e.g., nsubj, dobj) when representing a dependency path.\n",
        "\n",
        "For the example sentence, “Frank Rosenblatt invented the perceptron”, we expect an output,\n",
        "\n",
        "<i> check the site for the image </i>"
      ],
      "metadata": {
        "id": "L7XEmHNTJULh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<hr>\n",
        "\n",
        "## 49. Extract the shortest path between two nouns\n",
        "Extract the shortest path for every pair of two nouns. Supposing that two nouns appear at the i-th and j-th positions (in words) in a sentence (i<j), the shortest path must satisfy the following specifications.\n",
        "\n",
        "* Nodes in a path are words in surface form\n",
        "* Nodes corresponding to the i-th and j-th words are replaced with X and Y, respectively.\n",
        "* Nodes are connected with either “ -> “ or “ <- “ from X to Y to represent a direction of a dependency.\n",
        "\n",
        "We can consider two types of dependency paths.\n",
        "\n",
        "* When the j-th word appears on the path from the i-th word to the root: the path from the i-th word to the j-th word\n",
        "* When the i-th and j-th words have the common ancestor (the k-th word) in the dependency tree: the path from the i-th word to the k-th word connected with “ <- “, followed by the path from the k-th word to the j-th word connected with “ -> “.\n",
        "\n",
        "For the example sentence, “Frank Rosenblatt invented the perceptron”, we expect an output,\n",
        "\n",
        "<i> check the site for the image </i>"
      ],
      "metadata": {
        "id": "IHREHv_mJfN9"
      }
    }
  ]
}